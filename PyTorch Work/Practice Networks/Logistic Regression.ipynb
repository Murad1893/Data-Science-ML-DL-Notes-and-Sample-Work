{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b6ff51-d5af-41ff-8bf0-5ff4bd80bc16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Logistic Regression using pytorch\n",
    "\n",
    "**Date:** 30/10/2021  \n",
    "**Author:** Murad Popattia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d03dc04-a0b9-42f9-b1c1-616406bd29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9d9437-a21a-4cf5-bcfb-58b4f1e30bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# important to give your model, samples\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    # should return len of the data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # returns the data element at the specified idx\n",
    "    def __getitem__(self, idx):\n",
    "        cur_sample = self.data[idx, :]\n",
    "        cur_target = self.targets[idx]\n",
    "        \n",
    "        # returns a dict of tensors\n",
    "        return {\n",
    "            \"sample\": torch.tensor(cur_sample, dtype=torch.float),\n",
    "            \"target\": torch.tensor(cur_target,  dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8383ec25-b3ac-41fd-8c76-7cb5c75d6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = make_classification(n_samples=1000)\n",
    "train_data, test_data, train_targets,test_targets = train_test_split(data, targets, stratify=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65154c-1717-4236-9611-96422fd7e087",
   "metadata": {},
   "source": [
    "Stratify is done for classification problems to deal with class imbalance when sampling for the training data. Returns the same number of samples for the all the classes as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d60cb45d-57b9-48bf-bd1f-db4697d84205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 375)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_targets[train_targets == 0]), len(train_targets[train_targets == 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9fe3aff3-23bb-439d-81f2-c039ae6d036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset  = CustomDataset(train_data, train_targets)\n",
    "test_dataset  = CustomDataset(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b854dba5-95d0-49a0-9747-98586b3c22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a4c2666-9c59-49f5-a879-65a1dd3d356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "def model(x,W,b):\n",
    "    return x.mm(W) + b # WX+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3216acc4-9878-4aaa-afbf-aacc3b929c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67935fa8-8156-4596-b5f2-4a57dd15324a",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2bf9240c-c4e4-435c-ba54-71ebc1344638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting requires grad for backprop\n",
    "W = torch.randn(20, 1, requires_grad = True)\n",
    "b = torch.randn(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e7e17ec8-6180-486a-b1f0-1d32d13aef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss per batch:  17.582083642482758\n",
      "Epoch: 1 Loss per batch:  5.556818822913981\n",
      "Epoch: 2 Loss per batch:  2.289998558924553\n",
      "Epoch: 3 Loss per batch:  1.0871505683010563\n",
      "Epoch: 4 Loss per batch:  0.5653844877601938\n",
      "Epoch: 5 Loss per batch:  0.32255866528151833\n",
      "Epoch: 6 Loss per batch:  0.2058113976480796\n",
      "Epoch: 7 Loss per batch:  0.14858027525800974\n",
      "Epoch: 8 Loss per batch:  0.12011661746618436\n",
      "Epoch: 9 Loss per batch:  0.10579177171940558\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "# training the model\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    counter = 0\n",
    "    # extract over a batch of samples for each epoch\n",
    "    for data in train_loader:\n",
    "        x_train = data[\"sample\"]\n",
    "        y_train = data[\"target\"]\n",
    "        \n",
    "        # W.grad is automatically shifted between zero and none by PyTorch\n",
    "        if W.grad is not None:\n",
    "            W.zero_grad()\n",
    "        \n",
    "        output = model (x_train, W, b)\n",
    "        # MSE\n",
    "        loss = torch.mean((y_train.view(-1) - output.view(-1)) ** 2) # .view(-1) essentially multiplies all dimensions togethers in a single array\n",
    "        epoch_loss = epoch_loss + loss.item()\n",
    "        \n",
    "        # calculating gradients for W, b\n",
    "        loss.backward() \n",
    "        \n",
    "        # updating the weight and bias\n",
    "        with torch.no_grad():\n",
    "            # disabling torch to update gradients here\n",
    "            W = W - lr * W.grad\n",
    "            b = b - lr * b.grad\n",
    "            \n",
    "        # enable the gradients\n",
    "        W.requires_grad_(True)\n",
    "        b.requires_grad_(True)\n",
    "        counter += 1 # incrementing counter for every batch item\n",
    "        \n",
    "    print(\"Epoch:\", epoch, \"Loss per batch: \", epoch_loss/counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba57634-a0d2-44c6-9ecf-4ee5adead247",
   "metadata": {},
   "source": [
    "### Calculting the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0fe8b275-ab18-4774-902c-96fc94f05c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x_test = data[\"sample\"]\n",
    "        y_test = data[\"target\"]\n",
    "        \n",
    "        output = model(x_test, W, b)\n",
    "        labels.append(y_test)\n",
    "        outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f88302bc-83a6-4a73-847b-b54bf28c5001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0.6680],\n",
       "          [0.4481],\n",
       "          [0.4526],\n",
       "          [0.1769]]),\n",
       "  tensor([[ 0.2613],\n",
       "          [-0.0996],\n",
       "          [ 0.2428],\n",
       "          [-0.0719]])],\n",
       " [tensor([1, 0, 1, 0]), tensor([1, 0, 0, 0])])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2], labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf3167-7951-4f58-afb9-7b805cb9bd07",
   "metadata": {},
   "source": [
    "As output and labels are a list of tensors hence we can use *torch.cat()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d6121a3f-0057-4c88-b663-01b6babc928e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961664"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(torch.cat(labels).view(-1), torch.cat(outputs).view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece53aa-0a79-442d-80ff-ff762abd21d0",
   "metadata": {},
   "source": [
    "### Trying with random W and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3fddc4c3-d960-46ea-aa6e-5787ee0c30be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17260799999999998"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting requires grad for backprop\n",
    "W = torch.randn(20, 1, requires_grad = True)\n",
    "b = torch.randn(1, requires_grad = True)\n",
    "\n",
    "outputs = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        x_test = data[\"sample\"]\n",
    "        y_test = data[\"target\"]\n",
    "        \n",
    "        output = model(x_test, W, b)\n",
    "        labels.append(y_test)\n",
    "        outputs.append(output)\n",
    "\n",
    "metrics.roc_auc_score(torch.cat(labels).view(-1), torch.cat(outputs).view(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
