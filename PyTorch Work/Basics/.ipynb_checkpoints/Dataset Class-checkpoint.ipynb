{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd81d18-96b4-4e54-8c84-4af57f1f5c4d",
   "metadata": {},
   "source": [
    "### Dataset Class and DataLoaders\n",
    "\n",
    "Used in the backpropogation step in the NN \n",
    "\n",
    "**Date:** 29/10/2021  \n",
    "**Author:** Murad Popattia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7947c85b-ef5c-4346-bd1e-818344444305",
   "metadata": {},
   "source": [
    "### Basic Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84cd186-4b5e-46c6-9882-7658a37e3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed85dbd-c116-4ba9-82c3-2ccd214c3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important to give your model, samples\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    # should return len of the data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # returns the data element at the specified idx\n",
    "    def __getitem__(self, idx):\n",
    "        cur_sample = self.data[idx, :]\n",
    "        cur_target = self.targets[idx]\n",
    "        \n",
    "        # returns a dict of tensors\n",
    "        return {\n",
    "            \"sample\": torch.tensor(cur_sample, dtype=torch.float),\n",
    "            \"target\": torch.tensor(cur_target,  dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491369c3-9182-4aa9-8f30-11825c1956b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?make_classification\n",
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2b1071-4eff-4b65-b9df-0fb00f5d4bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets are binary\n",
    "data.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19233ba-e2b9-464c-926c-1730a0985320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample': tensor([-0.4422, -0.5011,  1.5107,  0.7165,  0.5521,  1.0575, -1.2364, -0.1809,\n",
      "         0.2105,  0.9634,  0.2448, -2.1240,  0.2823, -0.4810, -0.8553, -0.2054,\n",
      "         0.1008,  0.2937,  0.6091, -0.6417]), 'target': tensor(0)}\n"
     ]
    }
   ],
   "source": [
    "# Looping over the dataset class\n",
    "\n",
    "custom_dataset = CustomDataset(data=data, targets=targets)\n",
    "\n",
    "for sample in custom_dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20494aa0-6847-4630-a8ed-518e5f92b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([-0.4422, -0.5011,  1.5107,  0.7165,  0.5521,  1.0575, -1.2364, -0.1809,\n",
       "          0.2105,  0.9634,  0.2448, -2.1240,  0.2823, -0.4810, -0.8553, -0.2054,\n",
       "          0.1008,  0.2937,  0.6091, -0.6417]),\n",
       " 'target': tensor(0)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee31f0-df15-4a1c-be53-769202ccfa16",
   "metadata": {},
   "source": [
    "### Dataset class for basic NLP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98713106-7b0a-40e6-aac3-cf29a57eecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification/regression probs\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets, tokenizer):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx, :]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        # here we would need to tokenize the text label before returning\n",
    "        input_ids = tokenizer(text)\n",
    "        # the tokenizer can return something like [101, 12, 23, 44, ....] where 101 can be the <s> etc.\n",
    "        \n",
    "        # returns a dict of tensors\n",
    "        return {\n",
    "            \"text\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target,  dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb9639-8e03-4e96-b024-de3ecab543a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset class for basic Vision Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f12161-caae-4397-b9d0-4c361a4aa5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read the image from the paths here\n",
    "class CustomDataset:\n",
    "    def __init__(self, image_paths, targets, augmentations=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.augmentations = augmentations\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tagret = self.targets[idx]\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # opencv reads in BGR format so we need to convert them\n",
    "        \n",
    "        # applying augmentations\n",
    "        # you can use https://albumentations.ai/ \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "            \n",
    "        # pytorch expects images in channel first format -> c x h x w\n",
    "        image = np.tranpose(image, (2,0,1)).astype(np.float32)\n",
    "            \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.long),\n",
    "            \"target\": torch.tensor(target,  dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045e9ab-78d1-4671-8452-09b298b6ae4d",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "Data needs to be passed in batches to pass it to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cdc3872-6202-4f32-a030-08849f742c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important to give your model, samples\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    # should return len of the data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    # returns the data element at the specified idx\n",
    "    def __getitem__(self, idx):\n",
    "        cur_sample = self.data[idx, :]\n",
    "        cur_target = self.targets[idx]\n",
    "        \n",
    "        # returns a dict of tensors\n",
    "        return {\n",
    "            \"sample\": torch.tensor(cur_sample, dtype=torch.float),\n",
    "            \"target\": torch.tensor(cur_target,  dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f7e47b-65b0-41ee-b556-b9ca27a77791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?make_classification\n",
    "data, targets = make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b19139-9e72-4d1b-a5b6-6fdd7f3d8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee327a1-cc59-47be-8c86-4b984cb3ac45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5c5a54-9ab3-42f0-85b6-0b204b48b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?torch.autils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a141e1-53af-4ab4-b5c2-43c29336b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataloader\n",
    "# jupyter notebook does not support num_workers > 0 hence kept to 0 here \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=4, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3346a79e-3e51-444d-8b06-f34df1ad8bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x26c49841370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88384ce-d207-43b9-9c93-bd62ea932502",
   "metadata": {},
   "source": [
    "**train_loader** is now my generator that is supplying the data in batches instead of sending all in once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c54865-a2e6-45f9-862d-29392f2ddd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data[\"sample\"].shape)\n",
    "    print(data[\"target\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f824c2-f0d7-4752-a281-2ddcff0afa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):\n",
    "#     for data in train_loader:\n",
    "#         x = data[\"sample\"]\n",
    "#         y = data[\"targets\"]\n",
    "#         outputs = model(x,y)\n",
    "        \n",
    "#         # calculate loss\n",
    "#         # loss = ...\n",
    "        \n",
    "#         # loss.backwards()\n",
    "#         #...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
